# -*- coding: utf-8 -*-
"""Day#13_KNN_LR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/154qIPIhbzOqVsz83q-6wWA6gAbglFDpA

# Income Prediction
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing the required libraries
# To ignore warnings
import warnings
warnings.filterwarnings("ignore")
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import pickle
from sklearn.metrics import classification_report,confusion_matrix

# Reading the csv file and putting it into 'df' object.
df = pd.read_csv('adult_dataset.csv')

# select all categorical variables
df_categorical = df.select_dtypes(include=['object'])

# checking whether any other columns contain a "?"
df_categorical.apply(lambda x: x=="?", axis=0).sum()

"""### There are 1836 rows with missing values, which is about 5% of the total data. We choose to simply drop these rows."""

# dropping the rows having missing values in workclass
df = df[df['workclass'] != '?']
df = df[df['occupation'] != '?']
df = df[df['native.country'] != '?']
df.head()

"""# Data Preprocessing"""
df= df.dropna(axis=0, subset=['income'])
df.drop(['fnlwgt','education.num','native.country','marital.status','occupation'],inplace=True,axis=1)
from sklearn import preprocessing
# select all categorical variables
df_categorical = df.select_dtypes(include=['object'])
df_categorical.head()

# apply Label encoder to df_categorical
le = preprocessing.LabelEncoder()
df_categorical = df_categorical.apply(le.fit_transform)
print("mmmmmmmmmmmmmmmmmm",le.classes_)
df_categorical.head()

# concat df_categorical with original df
df = df.drop(df_categorical.columns, axis=1)
df = pd.concat([df, df_categorical], axis=1)
df.head()

# convert target variable income to categorical
df['income'] = df['income'].astype('category')
df['income'].head()

"""# Data Modelding"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

# Putting feature variable to X
X = df.drop('income',axis=1)
print(X.columns)
# sc = MinMaxScaler(feature_range=(0, 1))
# X = sc.fit_transform(X)
# Putting response variable to y
y = df['income']

# Splitting the data into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 99)
X_train.shape

"""## Random Forests"""



from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=150)
rfc.fit(X_train, y_train)
rfc_pred = rfc.predict(X_test)
print(classification_report(y_test,rfc_pred))
print(confusion_matrix(y_test,rfc_pred))
n= 650
print (rfc_pred[n])
print(X_test.values[n])

pickle.dump(rfc, open("ml_model.pkl", "wb"))
# pickle.dump(sc, open("scaler.pkl", "wb"))